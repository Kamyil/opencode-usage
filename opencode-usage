#!/usr/bin/env bash
set -euo pipefail

usage() {
	cat <<'EOF'
Usage: opencode-usage [options]

Summarize OpenCode usage for a given month from the SQLite DB.

Options:
  --db PATH                 Path to opencode.db (default: ~/.local/share/opencode/opencode.db)
  --month YYYY-MM           Month to report (default: current month)
  --category NAME:PATH      Assign project path prefix to category (repeatable)
  --default-category NAME   Bucket name for uncategorized paths (default: other)
  --top N                   Top projects to list per bucket (default: 5)
  --input-rate NUM          Cost per 1M input tokens
  --output-rate NUM         Cost per 1M output tokens
  --reasoning-rate NUM      Cost per 1M reasoning tokens (default: input-rate)
  --cache-read-rate NUM     Cost per 1M cache read tokens
  --cache-write-rate NUM    Cost per 1M cache write tokens
  --currency SYMBOL         Currency symbol for cost output (default: $)
  --by-model                Show token breakdown by model/provider per category
  --tools                   Show tool usage breakdown per category
  --diff-stats              Show lines of code added/deleted per category
  --time-stats              Show session duration and time-of-day analysis
  --months N                Show trends for the last N months
  --cost                    Show actual cost from provider (if reported)
  --todos                   Show todo/task completion statistics
  --titles                  Show top session titles per category
  --forks                   Show forked session statistics
  --json                    Output report as JSON
  --csv                     Output overview as CSV
  --pretty                  Pretty-print output with box drawing and bars
  --help                    Show this help

Examples:
  opencode-usage --category work:~/Work --category personal:~/Personal
  opencode-usage --month 2026-02 --category work:~/Work --category personal:~/Personal
  opencode-usage --category client:~/Clients --category hobby:~/Hobby
  opencode-usage --input-rate 5 --output-rate 15 --currency "$"
EOF
}

expand_path() {
	local value=$1
	case "$value" in
		"~") printf '%s' "$HOME" ;;
		"~/"*) printf '%s/%s' "$HOME" "${value:2}" ;;
		*) printf '%s' "$value" ;;
	esac
}

sql_escape() {
	local value=$1
	value=${value//\'/\'\'}
	printf '%s' "$value"
}

json_escape() {
	local value=$1
	value=${value//\\/\\\\}
	value=${value//\"/\\\"}
	value=${value//$'\n'/\\n}
	value=${value//$'\t'/\\t}
	value=${value//$'\r'/\\r}
	printf '%s' "$value"
}

csv_escape() {
	local value=$1
	if [[ "$value" == *[,\"$'\n']* ]]; then
		value=${value//\"/\"\"}
		printf '"%s"' "$value"
	else
		printf '%s' "$value"
	fi
}

build_like_clause() {
	local clause=""
	local prefix
	for prefix in "$@"; do
		prefix=$(expand_path "$prefix")
		prefix=${prefix%/}
		if [[ -z "$prefix" ]]; then
			continue
		fi
		if [[ -n "$clause" ]]; then
			clause+=" or "
		fi
		clause+="worktree like '$(sql_escape "$prefix")%'"
	done
	if [[ -z "$clause" ]]; then
		clause="0"
	fi
	printf '%s' "$clause"
}

add_category_prefix() {
	local name=$1
	local prefix=$2
	if [[ -z "$name" || -z "$prefix" ]]; then
		return 1
	fi
	if [[ -z "${CATEGORY_PREFIXES[$name]+x}" ]]; then
		CATEGORY_PREFIXES[$name]=""
		CATEGORY_NAMES+=("$name")
	fi
	if [[ -n "${CATEGORY_PREFIXES[$name]}" ]]; then
		CATEGORY_PREFIXES[$name]+=$'\n'
	fi
	CATEGORY_PREFIXES[$name]+="$prefix"
}

category_clause() {
	local name=$1
	local value=${CATEGORY_PREFIXES[$name]-}
	local prefixes=()
	if [[ -n "$value" ]]; then
		readarray -t prefixes <<< "$value"
	fi
	build_like_clause "${prefixes[@]}"
}

format_table() {
	if command -v column >/dev/null 2>&1; then
		column -t -s $'\t'
	else
		cat
	fi
}

format_number() {
	local num=$1 int_part dec_part="" result="" i len
	if [[ "$num" =~ \. ]]; then
		int_part=${num%%.*}
		dec_part=${num#*.}
	else
		int_part=$num
	fi
	# Remove leading zeros/spaces but keep the number valid
	printf -v int_part '%d' "$int_part" 2>/dev/null || int_part=0
	# Handle negative numbers
	local sign=""
	if (( int_part < 0 )); then
		sign="-"
		int_part=$(( -int_part ))
	fi
	local s="$int_part"
	len=${#s}
	for (( i=0; i<len; i++ )); do
		if (( i > 0 && (len - i) % 3 == 0 )); then
			result+=","
		fi
		result+="${s:i:1}"
	done
	if [[ -n "$dec_part" ]]; then
		printf '%s%s.%s' "$sign" "$result" "$dec_part"
	else
		printf '%s%s' "$sign" "$result"
	fi
}

BAR_WIDTH=30

make_bar() {
	local pct=$1
	# Pure bash: multiply pct*BAR_WIDTH using integer math with 100x scaling
	# pct is like "45.23" — strip the dot to get integer hundredths
	local int_part=${pct%%.*}
	local dec_part=${pct#*.}
	# If no decimal point, dec_part equals int_part
	[[ "$dec_part" == "$pct" ]] && dec_part="0"
	# Pad or trim dec_part to exactly 2 digits
	dec_part="${dec_part}00"
	dec_part="${dec_part:0:2}"
	# pct_x100 = pct * 100 (e.g. 45.23 -> 4523)
	local pct_x100=$(( 10#$int_part * 100 + 10#$dec_part ))
	# filled = round(pct * BAR_WIDTH / 100) = round(pct_x100 * BAR_WIDTH / 10000)
	local filled=$(( (pct_x100 * BAR_WIDTH + 5000) / 10000 ))
	(( filled > BAR_WIDTH )) && filled=$BAR_WIDTH
	(( filled < 0 )) && filled=0
	local empty=$((BAR_WIDTH - filled))
	local bar=""
	for ((i = 0; i < filled; i++)); do bar+="█"; done
	for ((i = 0; i < empty; i++)); do bar+="░"; done
	printf '%s' "$bar"
}

BOLD=""
DIM=""
RESET=""
CYAN=""
GREEN=""
YELLOW=""
MAGENTA=""
WHITE=""

init_colors() {
	if [[ -t 1 ]]; then
		BOLD=$'\033[1m'
		DIM=$'\033[2m'
		RESET=$'\033[0m'
		CYAN=$'\033[36m'
		GREEN=$'\033[32m'
		YELLOW=$'\033[33m'
		MAGENTA=$'\033[35m'
		WHITE=$'\033[37m'
	fi
}

repeat_char() {
	local char=$1 count=$2 result=""
	for (( i=0; i<count; i++ )); do result+="$char"; done
	printf '%s' "$result"
}

box_top()    { printf '╭%s╮\n' "$(repeat_char '─' "$1")"; }
box_bottom() { printf '╰%s╯\n' "$(repeat_char '─' "$1")"; }
box_sep()    { printf '├%s┤\n' "$(repeat_char '─' "$1")"; }
box_line()   { printf '│ %-*s │\n' "$(($1 - 2))" "$2"; }

section_header() {
	local title=$1
	local w=60
	printf '\n'
	box_top $w
	box_line $w "${BOLD}${CYAN}$title${RESET}"
	box_bottom $w
}

DB_PATH="${DB_PATH:-$HOME/.local/share/opencode/opencode.db}"
MONTH=""
TOP_N=5
CURRENCY="${CURRENCY:-$}"

DEFAULT_CATEGORY="other"
declare -A CATEGORY_PREFIXES
CATEGORY_NAMES=()
PRETTY=false
BY_MODEL=false
SHOW_TOOLS=false
SHOW_DIFF_STATS=false
SHOW_TIME_STATS=false
SHOW_MONTHS=""
SHOW_COST=false
SHOW_TODOS=false
SHOW_TITLES=false
SHOW_FORKS=false
OUTPUT_FORMAT="text"

INPUT_RATE=""
OUTPUT_RATE=""
REASONING_RATE=""
CACHE_READ_RATE=""
CACHE_WRITE_RATE=""

while [[ $# -gt 0 ]]; do
	case "$1" in
		--db)
			DB_PATH=$2
			shift 2
			;;
		--month)
			MONTH=$2
			shift 2
			;;
		--category)
			if [[ "$2" != *:* ]]; then
				printf 'Invalid --category format. Use NAME:PATH.\n' >&2
				exit 1
			fi
			CATEGORY_NAME=${2%%:*}
			CATEGORY_PATH=${2#*:}
			if [[ -z "$CATEGORY_NAME" || -z "$CATEGORY_PATH" ]]; then
				printf 'Invalid --category format. Use NAME:PATH.\n' >&2
				exit 1
			fi
			add_category_prefix "$CATEGORY_NAME" "$CATEGORY_PATH"
			shift 2
			;;
		--default-category)
			DEFAULT_CATEGORY=$2
			shift 2
			;;
		--top)
			TOP_N=$2
			shift 2
			;;
		--input-rate)
			INPUT_RATE=$2
			shift 2
			;;
		--output-rate)
			OUTPUT_RATE=$2
			shift 2
			;;
		--reasoning-rate)
			REASONING_RATE=$2
			shift 2
			;;
		--cache-read-rate)
			CACHE_READ_RATE=$2
			shift 2
			;;
		--cache-write-rate)
			CACHE_WRITE_RATE=$2
			shift 2
			;;
		--currency)
			CURRENCY=$2
			shift 2
			;;
		--months)
			SHOW_MONTHS=$2
			shift 2
			;;
		--cost)
			SHOW_COST=true
			shift
			;;
		--todos)
			SHOW_TODOS=true
			shift
			;;
		--titles)
			SHOW_TITLES=true
			shift
			;;
		--forks)
			SHOW_FORKS=true
			shift
			;;
		--json)
			OUTPUT_FORMAT="json"
			shift
			;;
		--csv)
			OUTPUT_FORMAT="csv"
			shift
			;;
		--pretty)
			PRETTY=true
			shift
			;;
		--by-model)
			BY_MODEL=true
			shift
			;;
		--tools)
			SHOW_TOOLS=true
			shift
			;;
		--diff-stats)
			SHOW_DIFF_STATS=true
			shift
			;;
		--time-stats)
			SHOW_TIME_STATS=true
			shift
			;;
		--help|-h)
			usage
			exit 0
			;;
		*)
			printf 'Unknown argument: %s\n' "$1" >&2
			usage >&2
			exit 1
			;;
	esac
done

DB_PATH=$(expand_path "$DB_PATH")

if [[ "$OUTPUT_FORMAT" != "text" && "$PRETTY" == true ]]; then
	printf 'Error: --json/--csv cannot be combined with --pretty\n' >&2
	exit 1
fi

if [[ -z "${CATEGORY_NAMES[*]-}" ]]; then
	printf 'At least one --category NAME:PATH is required.\n' >&2
	usage >&2
	exit 1
fi

if [[ -n "$MONTH" ]]; then
	if [[ ! "$MONTH" =~ ^[0-9]{4}-[0-9]{2}$ ]]; then
		printf 'Invalid --month format. Use YYYY-MM.\n' >&2
		exit 1
	fi
	MONTH_START="${MONTH}-01"
	MONTH_END=$(sqlite3 "$DB_PATH" "select date('$MONTH_START','+1 month');")
else
	MONTH_START=$(sqlite3 "$DB_PATH" "select date('now','start of month');")
	MONTH_END=$(sqlite3 "$DB_PATH" "select date('now','start of month','+1 month');")
fi

if [[ -n "$SHOW_MONTHS" ]]; then
	if ! [[ "$SHOW_MONTHS" =~ ^[0-9]+$ ]] || (( SHOW_MONTHS < 1 )); then
		printf 'Invalid --months value. Must be a positive integer.\n' >&2
		exit 1
	fi
fi

CATEGORY_WHENS=""
for CATEGORY_NAME in "${CATEGORY_NAMES[@]}"; do
	CATEGORY_CLAUSE=$(category_clause "$CATEGORY_NAME")
	if [[ -n "$CATEGORY_WHENS" ]]; then
		CATEGORY_WHENS+=$'\n\t\t'
	fi
	CATEGORY_WHENS+="when $CATEGORY_CLAUSE then '$(sql_escape "$CATEGORY_NAME")'"
done

if [[ -n "$INPUT_RATE" && -z "$OUTPUT_RATE" ]]; then
	OUTPUT_RATE=$INPUT_RATE
fi
if [[ -n "$INPUT_RATE" && -z "$REASONING_RATE" ]]; then
	REASONING_RATE=$INPUT_RATE
fi

MATERIALIZE_SQL=$(cat <<EOF
create temp table categorized as
with params as (
	select (strftime('%s', '$MONTH_START')*1000) as month_start_ms,
	       (strftime('%s', '$MONTH_END')*1000) as month_end_ms
),
message_filtered as (
	select * from message m, params p
	where m.time_created >= p.month_start_ms and m.time_created < p.month_end_ms
),
session_counts as (
	select m.session_id, count(distinct m.id) as message_count
	from message_filtered m
	group by m.session_id
),
token_totals as (
	select p.session_id,
	       sum(coalesce(json_extract(p.data,'$.tokens.input'),0)) as input_tokens,
	       sum(coalesce(json_extract(p.data,'$.tokens.output'),0)) as output_tokens,
	       sum(coalesce(json_extract(p.data,'$.tokens.reasoning'),0)) as reasoning_tokens,
	       sum(coalesce(json_extract(p.data,'$.tokens.cache.read'),0)) as cache_read_tokens,
	       sum(coalesce(json_extract(p.data,'$.tokens.cache.write'),0)) as cache_write_tokens
	from part p, params pm
	where json_extract(p.data,'$.type')='step-finish'
	  and p.time_created >= pm.month_start_ms and p.time_created < pm.month_end_ms
	group by p.session_id
),
active_sessions as (
	select session_id from session_counts
	union
	select session_id from token_totals
),
combined as (
	select a.session_id,
	       s.project_id,
	       coalesce(sc.message_count,0) as message_count,
	       coalesce(tt.input_tokens,0) as input_tokens,
	       coalesce(tt.output_tokens,0) as output_tokens,
	       coalesce(tt.reasoning_tokens,0) as reasoning_tokens,
	       coalesce(tt.cache_read_tokens,0) as cache_read_tokens,
	       coalesce(tt.cache_write_tokens,0) as cache_write_tokens
	from active_sessions a
	join session s on s.id = a.session_id
	left join session_counts sc on sc.session_id = a.session_id
	left join token_totals tt on tt.session_id = a.session_id
),
with_projects as (
	select c.*, p.worktree, p.name
	from combined c
	join project p on p.id = c.project_id
)
select case
	$CATEGORY_WHENS
	else '$(sql_escape "$DEFAULT_CATEGORY")'
end as bucket,
*
from with_projects;
EOF
)

if [[ "$PRETTY" == true ]]; then
	init_colors
fi

if [[ "$PRETTY" == true ]]; then
	printf '\n'
	box_top 60
	box_line 60 "${BOLD}${CYAN}OpenCode Usage Report${RESET}"
	box_line 60 "${DIM}$MONTH_START to $MONTH_END${RESET}"
	box_bottom 60
elif [[ "$OUTPUT_FORMAT" == "text" ]]; then
	printf 'OpenCode usage for %s to %s (exclusive)\n\n' "$MONTH_START" "$MONTH_END"
fi

## --- Single sqlite3 session: materialize the CTE once, then query the temp table ---

# Build the per-bucket top-projects queries
TOP_PROJECT_QUERIES=""
for bucket in "${CATEGORY_NAMES[@]}"; do
	TOP_PROJECT_QUERIES+="
select '---PROJECTS:$(sql_escape "$bucket")';
select worktree || char(9) ||
       count(distinct session_id) || char(9) ||
       sum(message_count) || char(9) ||
       sum(input_tokens+output_tokens+reasoning_tokens)
from categorized
where bucket = '$(sql_escape "$bucket")'
group by worktree
order by sum(input_tokens+output_tokens+reasoning_tokens) desc
limit $TOP_N;
"
done

# Check if the default category needs its own section
BUCKET_PRESENT=false
for bucket in "${CATEGORY_NAMES[@]}"; do
	if [[ "$bucket" == "$DEFAULT_CATEGORY" ]]; then
		BUCKET_PRESENT=true
		break
	fi
done
if [[ "$BUCKET_PRESENT" == false ]]; then
	TOP_PROJECT_QUERIES+="
select '---PROJECTS:$(sql_escape "$DEFAULT_CATEGORY")';
select worktree || char(9) ||
       count(distinct session_id) || char(9) ||
       sum(message_count) || char(9) ||
       sum(input_tokens+output_tokens+reasoning_tokens)
from categorized
where bucket = '$(sql_escape "$DEFAULT_CATEGORY")'
group by worktree
order by sum(input_tokens+output_tokens+reasoning_tokens) desc
limit $TOP_N;
"
fi

# Build top session titles queries if requested
TITLE_QUERIES=""
if [[ "$SHOW_TITLES" == true ]]; then
	for bucket in "${CATEGORY_NAMES[@]}"; do
		TITLE_QUERIES+="
select '---TITLES:$(sql_escape "$bucket")';
select s.title || char(9) ||
       c.message_count || char(9) ||
       (c.input_tokens + c.output_tokens + c.reasoning_tokens)
from categorized c
join session s on s.id = c.session_id
where c.bucket = '$(sql_escape "$bucket")'
order by (c.input_tokens + c.output_tokens + c.reasoning_tokens) desc
limit $TOP_N;
"
	done
	if [[ "$BUCKET_PRESENT" == false ]]; then
		TITLE_QUERIES+="
select '---TITLES:$(sql_escape "$DEFAULT_CATEGORY")';
select s.title || char(9) ||
       c.message_count || char(9) ||
       (c.input_tokens + c.output_tokens + c.reasoning_tokens)
from categorized c
join session s on s.id = c.session_id
where c.bucket = '$(sql_escape "$DEFAULT_CATEGORY")'
order by (c.input_tokens + c.output_tokens + c.reasoning_tokens) desc
limit $TOP_N;
"
	fi
fi

# Build fork stats query if requested
FORK_QUERY=""
if [[ "$SHOW_FORKS" == true ]]; then
	FORK_QUERY="
select '---FORKS_SUMMARY';
select c.bucket || char(9) ||
       count(*) || char(9) ||
       count(distinct s.parent_id) || char(9) ||
       round(1.0 * count(*) / count(distinct s.parent_id), 1)
from categorized c
join session s on s.id = c.session_id
where s.parent_id is not null
group by c.bucket
order by c.bucket;

select '---FORKS_TOP';
select bucket || char(9) || title || char(9) || fork_count
from (
	select c.bucket,
	       parent_s.title,
	       count(*) as fork_count,
	       row_number() over (partition by c.bucket order by count(*) desc) as rn
	from categorized c
	join session s on s.id = c.session_id
	join session parent_s on parent_s.id = s.parent_id
	where s.parent_id is not null
	group by c.bucket, s.parent_id
)
where rn <= $TOP_N;
"
fi

# Build cost query if rates are set
# Build multi-month trends query if requested
MONTHS_QUERY=""
if [[ -n "$SHOW_MONTHS" ]]; then
	MONTHS_QUERY="
select '---MONTHS';
with month_range as (
	select strftime('%Y-%m', date('$MONTH_END', '-' || n || ' months')) as month_label,
	       strftime('%s', date('$MONTH_END', '-' || n || ' months')) * 1000 as ms_start,
	       strftime('%s', date('$MONTH_END', '-' || (n-1) || ' months')) * 1000 as ms_end
	from (
		select row_number() over () as n from message limit $SHOW_MONTHS
	)
),
session_first_msg as (
	select m.session_id, min(m.time_created) as first_msg_ts
	from message m
	group by m.session_id
),
session_month as (
	select sfm.session_id, mr.month_label
	from session_first_msg sfm
	join month_range mr on sfm.first_msg_ts >= mr.ms_start and sfm.first_msg_ts < mr.ms_end
),
session_tokens as (
	select pt.session_id,
	       sum(coalesce(json_extract(pt.data,'\$.tokens.input'),0)
	         + coalesce(json_extract(pt.data,'\$.tokens.output'),0)
	         + coalesce(json_extract(pt.data,'\$.tokens.reasoning'),0)) as tokens
	from part pt
	where json_extract(pt.data,'\$.type')='step-finish'
	group by pt.session_id
),
month_categorized as (
	select sm.month_label,
	       case
	           $CATEGORY_WHENS
	           else '$(sql_escape "$DEFAULT_CATEGORY")'
	       end as bucket,
	       sm.session_id,
	       coalesce(st.tokens, 0) as tokens
	from session_month sm
	join session s on s.id = sm.session_id
	join project p on p.id = s.project_id
	left join session_tokens st on st.session_id = sm.session_id
)
select month_label || char(9) ||
       bucket || char(9) ||
       count(distinct session_id) || char(9) ||
       sum(tokens)
from month_categorized
group by month_label, bucket
order by month_label, bucket;
"
fi

COST_QUERY=""
if [[ -n "$INPUT_RATE" || -n "$OUTPUT_RATE" || -n "$REASONING_RATE" || -n "$CACHE_READ_RATE" || -n "$CACHE_WRITE_RATE" ]]; then
	INPUT_RATE=${INPUT_RATE:-0}
	OUTPUT_RATE=${OUTPUT_RATE:-0}
	REASONING_RATE=${REASONING_RATE:-0}
	CACHE_READ_RATE=${CACHE_READ_RATE:-0}
	CACHE_WRITE_RATE=${CACHE_WRITE_RATE:-0}
	COST_QUERY="
select '---COST';
select bucket || char(9) ||
       round((sum(input_tokens) * $INPUT_RATE
            + sum(output_tokens) * $OUTPUT_RATE
            + sum(reasoning_tokens) * $REASONING_RATE
            + sum(cache_read_tokens) * $CACHE_READ_RATE
            + sum(cache_write_tokens) * $CACHE_WRITE_RATE) / 1000000.0, 4)
from categorized
group by bucket
order by bucket;
"
fi

MODEL_QUERY=""
if [[ "$BY_MODEL" == true ]]; then
	MODEL_QUERY="
select '---MODELS';
select c.bucket || char(9) ||
       coalesce(ms.provider || '/' || ms.model_id, 'unknown') || char(9) ||
       sum(c.input_tokens) || char(9) ||
       sum(c.output_tokens) || char(9) ||
       sum(c.reasoning_tokens) || char(9) ||
       sum(c.input_tokens + c.output_tokens + c.reasoning_tokens) || char(9) ||
       count(distinct c.session_id) || char(9) ||
       sum(c.message_count) || char(9) ||
       round(100.0 * sum(c.input_tokens + c.output_tokens + c.reasoning_tokens) /
         nullif(sum(sum(c.input_tokens + c.output_tokens + c.reasoning_tokens)) over (partition by c.bucket), 0), 1)
from categorized c
left join (
  select session_id,
         json_extract(data, '$.model.providerID') as provider,
         json_extract(data, '$.model.modelID') as model_id,
         row_number() over (partition by session_id order by count(*) desc) as rn
  from message
  where json_extract(data, '$.model.modelID') is not null
  group by session_id, json_extract(data, '$.model.providerID'), json_extract(data, '$.model.modelID')
) ms on ms.session_id = c.session_id and ms.rn = 1
group by c.bucket, coalesce(ms.provider || '/' || ms.model_id, 'unknown')
order by c.bucket, sum(c.input_tokens + c.output_tokens + c.reasoning_tokens) desc;
"
fi

TOOLS_QUERY=""
if [[ "$SHOW_TOOLS" == true ]]; then
	TOOLS_QUERY="
select '---TOOLS';
select c.bucket || char(9) ||
       coalesce(json_extract(p.data, '$.tool'), 'unknown') || char(9) ||
       count(*) || char(9) ||
       round(100.0 * count(*) /
         nullif(sum(count(*)) over (partition by c.bucket), 0), 1)
from categorized c
join part p on p.session_id = c.session_id
where json_extract(p.data, '$.type') = 'tool'
  and p.time_created >= (strftime('%s','$MONTH_START')*1000)
  and p.time_created < (strftime('%s','$MONTH_END')*1000)
group by c.bucket, coalesce(json_extract(p.data, '$.tool'), 'unknown')
order by c.bucket, count(*) desc;
"
fi

DIFF_STATS_QUERY=""
if [[ "$SHOW_DIFF_STATS" == true ]]; then
	DIFF_STATS_QUERY="
select '---DIFFSTATS';
select c.bucket || char(9) ||
       coalesce(sum(s.summary_additions), 0) || char(9) ||
       coalesce(sum(s.summary_deletions), 0) || char(9) ||
       coalesce(sum(s.summary_files), 0) || char(9) ||
       count(distinct case when coalesce(s.summary_additions,0) > 0 or coalesce(s.summary_deletions,0) > 0 then c.session_id end)
from categorized c
join session s on s.id = c.session_id
group by c.bucket
order by c.bucket;
"
fi

TIME_STATS_QUERY=""
if [[ "$SHOW_TIME_STATS" == true ]]; then
	TIME_STATS_QUERY="
select '---TIMESTATS';
select c.bucket || char(9) ||
       round(avg((s.time_updated - s.time_created) / 1000.0 / 60.0), 1) || char(9) ||
       round(sum((s.time_updated - s.time_created) / 1000.0 / 3600.0), 1) || char(9) ||
       max((s.time_updated - s.time_created) / 1000 / 60) || char(9) ||
       round(sum((s.time_updated - s.time_created) / 1000.0 / 3600.0) / count(distinct c.session_id), 1)
from categorized c
join session s on s.id = c.session_id
group by c.bucket
order by c.bucket;

select '---HOURSTATS';
select c.bucket || char(9) ||
       cast(strftime('%H', s.time_created / 1000, 'unixepoch', 'localtime') as integer) || char(9) ||
       count(distinct c.session_id)
from categorized c
join session s on s.id = c.session_id
group by c.bucket, cast(strftime('%H', s.time_created / 1000, 'unixepoch', 'localtime') as integer)
order by c.bucket, cast(strftime('%H', s.time_created / 1000, 'unixepoch', 'localtime') as integer);
"
fi

# Build actual cost query if requested
ACTUAL_COST_QUERY=""
if [[ "$SHOW_COST" == true ]]; then
	ACTUAL_COST_QUERY="
select '---ACTUAL_COST';
select bucket || char(9) ||
       round(sum(actual_cost), 6) || char(9) ||
       count(distinct session_id)
from (
	select c.bucket, c.session_id,
	       coalesce(json_extract(p.data,'\$.cost'), 0) as actual_cost
	from categorized c
	join part p on p.session_id = c.session_id
	where json_extract(p.data,'\$.type')='step-finish'
)
group by bucket
order by bucket;
"
fi

# Build todo stats query if requested
TODO_QUERY=""
if [[ "$SHOW_TODOS" == true ]]; then
	TODO_QUERY="
select '---TODOS_STATUS';
select c.bucket || char(9) ||
       t.status || char(9) ||
       count(*)
from categorized c
join todo t on t.session_id = c.session_id
group by c.bucket, t.status
order by c.bucket, t.status;

select '---TODOS_PRIORITY';
select c.bucket || char(9) ||
       t.priority || char(9) ||
       count(*)
from categorized c
join todo t on t.session_id = c.session_id
group by c.bucket, t.priority
order by c.bucket,
  case t.priority
    when 'critical' then 1
    when 'high' then 2
    when 'medium' then 3
    when 'low' then 4
    else 5
  end;
"
fi

ALL_DATA=$(sqlite3 "$DB_PATH" "
$MATERIALIZE_SQL

select '---OVERVIEW';
select bucket || char(9) ||
       count(distinct session_id) || char(9) ||
       sum(message_count) || char(9) ||
       sum(input_tokens) || char(9) ||
       sum(output_tokens) || char(9) ||
       sum(reasoning_tokens) || char(9) ||
       sum(cache_read_tokens) || char(9) ||
       sum(cache_write_tokens) || char(9) ||
       sum(input_tokens+output_tokens+reasoning_tokens) || char(9) ||
       sum(input_tokens+output_tokens+reasoning_tokens+cache_read_tokens+cache_write_tokens)
from categorized
group by bucket
order by bucket;

select '---PCT';
select bucket || char(9) ||
       round(100.0*sum(input_tokens+output_tokens+reasoning_tokens)
             / nullif(sum(sum(input_tokens+output_tokens+reasoning_tokens)) over (),0), 2) || char(9) ||
       round(100.0*sum(input_tokens+output_tokens+reasoning_tokens+cache_read_tokens+cache_write_tokens)
             / nullif(sum(sum(input_tokens+output_tokens+reasoning_tokens+cache_read_tokens+cache_write_tokens)) over (),0), 2) || char(9) ||
       round(100.0*sum(message_count)
             / nullif(sum(sum(message_count)) over (),0), 2) || char(9) ||
       round(100.0*count(distinct session_id)
             / nullif(sum(count(distinct session_id)) over (),0), 2)
from categorized
group by bucket
order by bucket;

$TOP_PROJECT_QUERIES

$TITLE_QUERIES

select '---SUMMARY';
select bucket || char(9) ||
       round(100.0*sum(input_tokens+output_tokens+reasoning_tokens)
             / nullif(sum(sum(input_tokens+output_tokens+reasoning_tokens)) over (),0), 1) || char(9) ||
       round(100.0*sum(message_count)
             / nullif(sum(sum(message_count)) over (),0), 1) || char(9) ||
       sum(message_count) || char(9) ||
       sum(input_tokens+output_tokens+reasoning_tokens)
from categorized
group by bucket
order by sum(input_tokens+output_tokens+reasoning_tokens) desc;

$COST_QUERY

$MODEL_QUERY

$TOOLS_QUERY
$DIFF_STATS_QUERY

$TIME_STATS_QUERY

$MONTHS_QUERY

$ACTUAL_COST_QUERY

$TODO_QUERY

$FORK_QUERY
")

## --- Parse the combined output into sections ---

OVERVIEW_DATA=""
PCT_DATA=""
SUMMARY_DATA=""
COST_DATA=""
MODEL_DATA=""
TOOLS_DATA=""
DIFF_STATS_DATA=""
TIME_STATS_DATA=""
HOUR_STATS_DATA=""
MONTHS_DATA=""
ACTUAL_COST_DATA=""
TODOS_STATUS_DATA=""
TODOS_PRIORITY_DATA=""
FORKS_SUMMARY_DATA=""
FORKS_TOP_DATA=""
declare -A PROJECT_DATA_MAP
declare -A TITLE_DATA_MAP
CURRENT_SECTION=""

while IFS= read -r line; do
	case "$line" in
		---OVERVIEW) CURRENT_SECTION="overview"; continue ;;
		---PCT) CURRENT_SECTION="pct"; continue ;;
		---PROJECTS:*) CURRENT_SECTION="projects:${line#---PROJECTS:}"; continue ;;
		---TITLES:*) CURRENT_SECTION="titles:${line#---TITLES:}"; continue ;;
		---SUMMARY) CURRENT_SECTION="summary"; continue ;;
		---COST) CURRENT_SECTION="cost"; continue ;;
		---MODELS) CURRENT_SECTION="models"; continue ;;
		---TOOLS) CURRENT_SECTION="tools"; continue ;;
		---DIFFSTATS) CURRENT_SECTION="diffstats"; continue ;;
		---TIMESTATS) CURRENT_SECTION="timestats"; continue ;;
		---HOURSTATS) CURRENT_SECTION="hourstats"; continue ;;
		---MONTHS) CURRENT_SECTION="months"; continue ;;
		---ACTUAL_COST) CURRENT_SECTION="actual_cost"; continue ;;
		---TODOS_STATUS) CURRENT_SECTION="todos_status"; continue ;;
		---TODOS_PRIORITY) CURRENT_SECTION="todos_priority"; continue ;;
		---FORKS_SUMMARY) CURRENT_SECTION="forks_summary"; continue ;;
		---FORKS_TOP) CURRENT_SECTION="forks_top"; continue ;;
	esac
	case "$CURRENT_SECTION" in
		overview)
			[[ -n "$OVERVIEW_DATA" ]] && OVERVIEW_DATA+=$'\n'
			OVERVIEW_DATA+="$line"
			;;
		pct)
			[[ -n "$PCT_DATA" ]] && PCT_DATA+=$'\n'
			PCT_DATA+="$line"
			;;
		projects:*)
			local_bucket=${CURRENT_SECTION#projects:}
			if [[ -n "${PROJECT_DATA_MAP[$local_bucket]+x}" ]]; then
				PROJECT_DATA_MAP[$local_bucket]+=$'\n'
			fi
			PROJECT_DATA_MAP[$local_bucket]+="$line"
			;;
		titles:*)
			local_bucket=${CURRENT_SECTION#titles:}
			if [[ -n "${TITLE_DATA_MAP[$local_bucket]+x}" ]]; then
				TITLE_DATA_MAP[$local_bucket]+=$'\n'
			fi
			TITLE_DATA_MAP[$local_bucket]+="$line"
			;;
		summary)
			[[ -n "$SUMMARY_DATA" ]] && SUMMARY_DATA+=$'\n'
			SUMMARY_DATA+="$line"
			;;
		cost)
			[[ -n "$COST_DATA" ]] && COST_DATA+=$'\n'
			COST_DATA+="$line"
			;;
		models)
			[[ -n "$MODEL_DATA" ]] && MODEL_DATA+=$'\n'
			MODEL_DATA+="$line"
			;;
		tools)
			[[ -n "$TOOLS_DATA" ]] && TOOLS_DATA+=$'\n'
			TOOLS_DATA+="$line"
			;;
		diffstats)
			[[ -n "$DIFF_STATS_DATA" ]] && DIFF_STATS_DATA+=$'\n'
			DIFF_STATS_DATA+="$line"
			;;
		timestats)
			[[ -n "$TIME_STATS_DATA" ]] && TIME_STATS_DATA+=$'\n'
			TIME_STATS_DATA+="$line"
			;;
		hourstats)
			[[ -n "$HOUR_STATS_DATA" ]] && HOUR_STATS_DATA+=$'\n'
			HOUR_STATS_DATA+="$line"
			;;
		months)
			[[ -n "$MONTHS_DATA" ]] && MONTHS_DATA+=$'\n'
			MONTHS_DATA+="$line"
			;;
		actual_cost)
			[[ -n "$ACTUAL_COST_DATA" ]] && ACTUAL_COST_DATA+=$'\n'
			ACTUAL_COST_DATA+="$line"
			;;
		todos_status)
			[[ -n "$TODOS_STATUS_DATA" ]] && TODOS_STATUS_DATA+=$'\n'
			TODOS_STATUS_DATA+="$line"
			;;
		todos_priority)
			[[ -n "$TODOS_PRIORITY_DATA" ]] && TODOS_PRIORITY_DATA+=$'\n'
			TODOS_PRIORITY_DATA+="$line"
			;;
		forks_summary)
			[[ -n "$FORKS_SUMMARY_DATA" ]] && FORKS_SUMMARY_DATA+=$'\n'
			FORKS_SUMMARY_DATA+="$line"
			;;
		forks_top)
			[[ -n "$FORKS_TOP_DATA" ]] && FORKS_TOP_DATA+=$'\n'
			FORKS_TOP_DATA+="$line"
			;;
	esac
done <<< "$ALL_DATA"

## --- Render output ---

if [[ "$OUTPUT_FORMAT" == "json" ]]; then
	# --- JSON output ---
	printf '{\n'
	printf '  "period": {"start": "%s", "end": "%s"},\n' "$MONTH_START" "$MONTH_END"

	# Overview array
	printf '  "overview": [\n'
	local_first=true
	while IFS=$'\t' read -r bucket sessions messages input output reasoning cread cwrite total total_cache; do
		[[ "$local_first" == true ]] && local_first=false || printf ',\n'
		printf '    {"category": "%s", "sessions": %s, "messages": %s, "input_tokens": %s, "output_tokens": %s, "reasoning_tokens": %s, "cache_read_tokens": %s, "cache_write_tokens": %s, "total_tokens": %s, "total_tokens_with_cache": %s}' \
			"$(json_escape "$bucket")" "$sessions" "$messages" "$input" "$output" "$reasoning" "$cread" "$cwrite" "$total" "$total_cache"
	done <<< "$OVERVIEW_DATA"
	printf '\n  ],\n'

	# Percentages array
	printf '  "percentages": [\n'
	local_first=true
	while IFS=$'\t' read -r bucket pct_tokens pct_cache pct_msgs pct_sess; do
		[[ "$local_first" == true ]] && local_first=false || printf ',\n'
		printf '    {"category": "%s", "pct_tokens": %s, "pct_tokens_with_cache": %s, "pct_messages": %s, "pct_sessions": %s}' \
			"$(json_escape "$bucket")" "$pct_tokens" "$pct_cache" "$pct_msgs" "$pct_sess"
	done <<< "$PCT_DATA"
	printf '\n  ],\n'

	# Top projects per bucket
	BUCKETS=("${CATEGORY_NAMES[@]}")
	if [[ "$BUCKET_PRESENT" == false ]]; then
		BUCKETS+=("$DEFAULT_CATEGORY")
	fi
	printf '  "top_projects": {\n'
	local_bfirst=true
	for bucket in "${BUCKETS[@]}"; do
		[[ "$local_bfirst" == true ]] && local_bfirst=false || printf ',\n'
		printf '    "%s": [\n' "$(json_escape "$bucket")"
		PROJECT_DATA="${PROJECT_DATA_MAP[$bucket]-}"
		if [[ -n "$PROJECT_DATA" ]]; then
			local_first=true
			while IFS=$'\t' read -r worktree sessions messages tokens; do
				[[ "$local_first" == true ]] && local_first=false || printf ',\n'
				printf '      {"worktree": "%s", "sessions": %s, "messages": %s, "tokens": %s}' \
					"$(json_escape "$worktree")" "$sessions" "$messages" "$tokens"
			done <<< "$PROJECT_DATA"
			printf '\n'
		fi
		printf '    ]'
	done
	printf '\n  },\n'

	# Summary array
	printf '  "summary": [\n'
	local_first=true
	while IFS=$'\t' read -r bucket pct_tokens pct_msgs messages tokens; do
		[[ "$local_first" == true ]] && local_first=false || printf ',\n'
		printf '    {"category": "%s", "pct_tokens": %s, "pct_messages": %s, "messages": %s, "tokens": %s}' \
			"$(json_escape "$bucket")" "$pct_tokens" "$pct_msgs" "$messages" "$tokens"
	done <<< "$SUMMARY_DATA"
	printf '\n  ]'

	# Cost (optional)
	if [[ -n "$COST_DATA" ]]; then
		printf ',\n  "cost": {\n'
		printf '    "currency": "%s",\n' "$(json_escape "$CURRENCY")"
		printf '    "rates": {"input": %s, "output": %s, "reasoning": %s, "cache_read": %s, "cache_write": %s},\n' \
			"${INPUT_RATE:-0}" "${OUTPUT_RATE:-0}" "${REASONING_RATE:-0}" "${CACHE_READ_RATE:-0}" "${CACHE_WRITE_RATE:-0}"
		printf '    "by_category": [\n'
		local_first=true
		while IFS=$'\t' read -r bucket cost; do
			[[ "$local_first" == true ]] && local_first=false || printf ',\n'
			printf '      {"category": "%s", "cost": %s}' "$(json_escape "$bucket")" "$cost"
		done <<< "$COST_DATA"
		printf '\n    ]\n  }'
	fi

	printf '\n}\n'

elif [[ "$OUTPUT_FORMAT" == "csv" ]]; then
	# --- CSV output ---
	printf 'category,sessions,messages,input_tokens,output_tokens,reasoning_tokens,cache_read_tokens,cache_write_tokens,total_tokens,total_tokens_with_cache\n'
	while IFS=$'\t' read -r bucket sessions messages input output reasoning cread cwrite total total_cache; do
		printf '%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\n' \
			"$(csv_escape "$bucket")" "$sessions" "$messages" "$input" "$output" "$reasoning" "$cread" "$cwrite" "$total" "$total_cache"
	done <<< "$OVERVIEW_DATA"

	# Percentages
	printf '\ncategory,pct_tokens,pct_tokens_with_cache,pct_messages,pct_sessions\n'
	while IFS=$'\t' read -r bucket pct_tokens pct_cache pct_msgs pct_sess; do
		printf '%s,%s,%s,%s,%s\n' \
			"$(csv_escape "$bucket")" "$pct_tokens" "$pct_cache" "$pct_msgs" "$pct_sess"
	done <<< "$PCT_DATA"

	# Top projects per bucket
	BUCKETS=("${CATEGORY_NAMES[@]}")
	if [[ "$BUCKET_PRESENT" == false ]]; then
		BUCKETS+=("$DEFAULT_CATEGORY")
	fi
	printf '\ncategory,worktree,sessions,messages,tokens\n'
	for bucket in "${BUCKETS[@]}"; do
		PROJECT_DATA="${PROJECT_DATA_MAP[$bucket]-}"
		if [[ -n "$PROJECT_DATA" ]]; then
			while IFS=$'\t' read -r worktree sessions messages tokens; do
				printf '%s,%s,%s,%s,%s\n' \
					"$(csv_escape "$bucket")" "$(csv_escape "$worktree")" "$sessions" "$messages" "$tokens"
			done <<< "$PROJECT_DATA"
		fi
	done

	# Summary
	printf '\ncategory,pct_tokens,pct_messages,messages,tokens\n'
	while IFS=$'\t' read -r bucket pct_tokens pct_msgs messages tokens; do
		printf '%s,%s,%s,%s,%s\n' \
			"$(csv_escape "$bucket")" "$pct_tokens" "$pct_msgs" "$messages" "$tokens"
	done <<< "$SUMMARY_DATA"

	# Cost (optional)
	if [[ -n "$COST_DATA" ]]; then
		printf '\ncategory,cost\n'
		while IFS=$'\t' read -r bucket cost; do
			printf '%s,%s\n' "$(csv_escape "$bucket")" "$cost"
		done <<< "$COST_DATA"
	fi

else
# --- Normal text/pretty output ---

if [[ "$PRETTY" == true ]]; then
	section_header "Overview"
	printf '\n'
	printf '  %-14s %10s %10s %18s %18s\n' \
		"${BOLD}Category${RESET}" "${BOLD}Sessions${RESET}" "${BOLD}Messages${RESET}" "${BOLD}Tokens${RESET}" "${BOLD}Tokens+Cache${RESET}"
	printf '  %-14s %10s %10s %18s %18s\n' \
		"──────────────" "──────────" "──────────" "──────────────────" "──────────────────"
	while IFS=$'\t' read -r bucket sessions messages _in _out _reason _cread _cwrite total total_cache; do
		printf '  %-14s %10s %10s %18s %18s\n' \
			"$bucket" "$(format_number "$sessions")" "$(format_number "$messages")" \
			"$(format_number "$total")" "$(format_number "$total_cache")"
	done <<< "$OVERVIEW_DATA"

	section_header "Usage Split"
	while IFS=$'\t' read -r bucket pct_tokens _pct_cache pct_msgs pct_sess; do
		printf '\n  %s%-14s%s\n' "$BOLD" "$bucket" "$RESET"
		printf '  Tokens   %s %6s%%\n' "$(make_bar "$pct_tokens")" "$pct_tokens"
		printf '  Messages %s %6s%%\n' "$(make_bar "$pct_msgs")" "$pct_msgs"
		printf '  Sessions %s %6s%%\n' "$(make_bar "$pct_sess")" "$pct_sess"
	done <<< "$PCT_DATA"
else
	printf '%s\n' "$OVERVIEW_DATA" | (
		printf 'bucket\tsessions\tmessages\tinput_tokens\toutput_tokens\treasoning_tokens\tcache_read_tokens\tcache_write_tokens\ttotal_tokens_no_cache\ttotal_tokens_with_cache\n'
		cat
	) | format_table

	printf '\nPercent split\n'
	printf '%s\n' "$PCT_DATA" | (
		printf 'bucket\tpct_tokens_no_cache\tpct_tokens_with_cache\tpct_messages\tpct_sessions\n'
		cat
	) | format_table
fi

BUCKETS=("${CATEGORY_NAMES[@]}")
if [[ "$BUCKET_PRESENT" == false ]]; then
	BUCKETS+=("$DEFAULT_CATEGORY")
fi

if [[ "$PRETTY" == true ]]; then
	section_header "Top Projects"
else
	printf '\nTop projects by tokens (no cache)\n'
fi

for bucket in "${BUCKETS[@]}"; do
	PROJECT_DATA="${PROJECT_DATA_MAP[$bucket]-}"
	if [[ "$PRETTY" == true ]]; then
		printf '\n  %s%s%s\n' "$BOLD" "$bucket" "$RESET"
		if [[ -z "$PROJECT_DATA" ]]; then
			printf '  %s(no data)%s\n' "$DIM" "$RESET"
			continue
		fi
		printf '  %-45s %10s %10s %18s\n' \
			"${DIM}Path${RESET}" "${DIM}Sessions${RESET}" "${DIM}Messages${RESET}" "${DIM}Tokens${RESET}"
		while IFS=$'\t' read -r worktree sessions messages tokens; do
			local_path=${worktree/#$HOME/\~}
			printf '  %-45s %10s %10s %18s\n' \
				"$local_path" "$(format_number "$sessions")" "$(format_number "$messages")" "$(format_number "$tokens")"
		done <<< "$PROJECT_DATA"
	else
		printf '\n%s\n' "$bucket"
		if [[ -n "$PROJECT_DATA" ]]; then
			printf '%s\n' "$PROJECT_DATA" | (
				printf 'worktree\tsessions\tmessages\ttotal_tokens_no_cache\n'
				cat
			) | format_table
		fi
	fi
done

if [[ "$SHOW_TITLES" == true ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Top Sessions by Tokens"
	else
		printf '\nTop sessions by tokens (no cache)\n'
	fi

	for bucket in "${BUCKETS[@]}"; do
		TITLE_DATA="${TITLE_DATA_MAP[$bucket]-}"
		if [[ "$PRETTY" == true ]]; then
			printf '\n  %s%s%s\n' "$BOLD" "$bucket" "$RESET"
			if [[ -z "$TITLE_DATA" ]]; then
				printf '  %s(no data)%s\n' "$DIM" "$RESET"
				continue
			fi
			printf '  %-50s %10s %18s\n' \
				"${DIM}Title${RESET}" "${DIM}Messages${RESET}" "${DIM}Tokens${RESET}"
			while IFS=$'\t' read -r title messages tokens; do
				# Truncate long titles
				if (( ${#title} > 48 )); then
					title="${title:0:45}..."
				fi
				printf '  %-50s %10s %18s\n' \
					"$title" "$(format_number "$messages")" "$(format_number "$tokens")"
			done <<< "$TITLE_DATA"
		else
			printf '\n%s\n' "$bucket"
			if [[ -n "$TITLE_DATA" ]]; then
				printf '%s\n' "$TITLE_DATA" | (
					printf 'title\tmessages\ttokens\n'
					cat
				) | format_table
			fi
		fi
	done
fi

if [[ "$PRETTY" == true ]]; then
	section_header "Summary"
	printf '\n'
	while IFS=$'\t' read -r bucket pct_tokens pct_msgs messages tokens; do
		printf '  %s%-14s%s  %s%% tokens  |  %s%% messages  |  %s msgs  |  %s tokens\n' \
			"$BOLD" "$bucket" "$RESET" \
			"$pct_tokens" "$pct_msgs" \
			"$(format_number "$messages")" "$(format_number "$tokens")"
	done <<< "$SUMMARY_DATA"
	printf '\n'
else
	printf '\n--- Summary ---\n'
	while IFS=$'\t' read -r bucket pct_tokens pct_msgs messages tokens; do
		printf '%s: %s%% tokens, %s%% messages (%s messages, %s tokens)\n' \
			"$bucket" "$pct_tokens" "$pct_msgs" "$messages" "$tokens"
	done <<< "$SUMMARY_DATA"
fi

if [[ -n "$COST_DATA" ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Cost Estimate (${CURRENCY} per 1M tokens)"
		printf '\n'
		while IFS=$'\t' read -r bucket cost; do
			printf '  %-14s %s%s\n' "$bucket" "$CURRENCY" "$cost"
		done <<< "$COST_DATA"
		printf '\n'
	else
		printf '\nCost estimate (%s per 1M tokens)\n' "$CURRENCY"
		printf '%s\n' "$COST_DATA" | (
			printf 'bucket\tcost\n'
			cat
		) | format_table
	fi
fi

if [[ -n "$MODEL_DATA" ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Model Breakdown"
		local_last_bucket=""
		while IFS=$'\t' read -r bucket model input_tok output_tok reasoning_tok total_tok sessions messages pct; do
			if [[ "$bucket" != "$local_last_bucket" ]]; then
				printf '\n  %s%s%s\n' "$BOLD" "$bucket" "$RESET"
				printf '  %-35s %10s %10s %18s %7s\n' \
					"${DIM}Model${RESET}" "${DIM}Sessions${RESET}" "${DIM}Messages${RESET}" "${DIM}Tokens${RESET}" "${DIM}   %${RESET}"
				local_last_bucket="$bucket"
			fi
			printf '  %-35s %10s %10s %18s %6s%%\n' \
				"$model" "$(format_number "$sessions")" "$(format_number "$messages")" \
				"$(format_number "$total_tok")" "$pct"
		done <<< "$MODEL_DATA"
		printf '\n'
	else
		printf '\nModel breakdown\n'
		printf '%s\n' "$MODEL_DATA" | (
			printf 'bucket\tmodel\tinput_tokens\toutput_tokens\treasoning_tokens\ttotal_tokens\tsessions\tmessages\tpct\n'
			cat
		) | format_table
	fi
fi

if [[ -n "$TOOLS_DATA" ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Tool Usage"
		local_last_bucket=""
		while IFS=$'\t' read -r bucket tool_name call_count pct; do
			if [[ "$bucket" != "$local_last_bucket" ]]; then
				printf '\n  %s%s%s\n' "$BOLD" "$bucket" "$RESET"
				printf '  %-25s %10s %7s\n' \
					"${DIM}Tool${RESET}" "${DIM}Calls${RESET}" "${DIM}   %${RESET}"
				local_last_bucket="$bucket"
			fi
			printf '  %-25s %10s %6s%%\n' \
				"$tool_name" "$(format_number "$call_count")" "$pct"
		done <<< "$TOOLS_DATA"
		printf '\n'
	else
		printf '\nTool usage\n'
		printf '%s\n' "$TOOLS_DATA" | (
			printf 'bucket\ttool\tcalls\tpct\n'
			cat
		) | format_table
	fi
fi

if [[ -n "$DIFF_STATS_DATA" ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Code Impact (Git Diff Stats)"
		printf '\n'
		printf '  %-14s %12s %12s %12s %10s\n' \
			"${BOLD}Category${RESET}" "${BOLD}${GREEN}+Added${RESET}" "${BOLD}${YELLOW}-Deleted${RESET}" "${BOLD}Net${RESET}" "${BOLD}Files${RESET}"
		printf '  %-14s %12s %12s %12s %10s\n' \
			"──────────────" "────────────" "────────────" "────────────" "──────────"
		while IFS=$'\t' read -r bucket additions deletions files sessions_with; do
			local_net=$(( additions - deletions ))
			printf '  %-14s %s%12s%s %s%12s%s %12s %10s\n' \
				"$bucket" \
				"$GREEN" "+$(format_number "$additions")" "$RESET" \
				"$YELLOW" "-$(format_number "$deletions")" "$RESET" \
				"$(format_number "$local_net")" \
				"$(format_number "$files")"
		done <<< "$DIFF_STATS_DATA"
		printf '\n'
	else
		printf '\nCode impact (git diff stats)\n'
		printf '%s\n' "$DIFF_STATS_DATA" | (
			printf 'bucket\tadditions\tdeletions\tfiles\tsessions_with_changes\n'
			cat
		) | format_table
	fi
fi

if [[ -n "$TIME_STATS_DATA" ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Session Duration"
		printf '\n'
		printf '  %-14s %12s %12s %12s\n' \
			"${BOLD}Category${RESET}" "${BOLD}Avg (min)${RESET}" "${BOLD}Max (min)${RESET}" "${BOLD}Total (hrs)${RESET}"
		printf '  %-14s %12s %12s %12s\n' \
			"──────────────" "────────────" "────────────" "────────────"
		while IFS=$'\t' read -r bucket avg_min total_hrs max_min _avg_hrs; do
			printf '  %-14s %12s %12s %12s\n' \
				"$bucket" "$avg_min" "$(format_number "$max_min")" "$total_hrs"
		done <<< "$TIME_STATS_DATA"
		printf '\n'

		if [[ -n "$HOUR_STATS_DATA" ]]; then
			section_header "Activity by Hour"
			# Find max count for scaling bars
			local_max=0
			while IFS=$'\t' read -r _bucket _hour count; do
				(( count > local_max )) && local_max=$count
			done <<< "$HOUR_STATS_DATA"

			local_last_bucket=""
			while IFS=$'\t' read -r bucket hour count; do
				if [[ "$bucket" != "$local_last_bucket" ]]; then
					printf '\n  %s%s%s\n' "$BOLD" "$bucket" "$RESET"
					local_last_bucket="$bucket"
				fi
				# Scale bar to max 20 chars
				if (( local_max > 0 )); then
					local_bar_len=$(( count * 20 / local_max ))
				else
					local_bar_len=0
				fi
				local_bar=""
				for (( i=0; i<local_bar_len; i++ )); do local_bar+="█"; done
				printf '  %02d:00  %s %s\n' "$hour" "$local_bar" "$count"
			done <<< "$HOUR_STATS_DATA"
			printf '\n'
		fi
	else
		printf '\nSession duration\n'
		printf '%s\n' "$TIME_STATS_DATA" | (
			printf 'bucket\tavg_duration_min\ttotal_hours\tmax_duration_min\tavg_hours_per_session\n'
			cat
		) | format_table

		if [[ -n "$HOUR_STATS_DATA" ]]; then
			printf '\nActivity by hour\n'
			printf '%s\n' "$HOUR_STATS_DATA" | (
				printf 'bucket\thour\tsessions\n'
				cat
			) | format_table
		fi
	fi
fi

if [[ -n "$MONTHS_DATA" ]]; then
	# Collect all months and buckets from the data
	declare -A MONTHS_MAP  # key="month|bucket" -> "sessions\ttokens"
	MONTH_LIST=()
	declare -A MONTH_SEEN
	declare -A BUCKET_SEEN_MONTHS
	BUCKET_LIST_MONTHS=()

	while IFS=$'\t' read -r month bucket sessions tokens; do
		MONTHS_MAP["$month|$bucket"]="${sessions}	${tokens}"
		if [[ -z "${MONTH_SEEN[$month]+x}" ]]; then
			MONTH_SEEN[$month]=1
			MONTH_LIST+=("$month")
		fi
		if [[ -z "${BUCKET_SEEN_MONTHS[$bucket]+x}" ]]; then
			BUCKET_SEEN_MONTHS[$bucket]=1
			BUCKET_LIST_MONTHS+=("$bucket")
		fi
	done <<< "$MONTHS_DATA"

	if [[ "$PRETTY" == true ]]; then
		section_header "Multi-Month Trends (Sessions)"
		printf '\n'
		# Header: Month + one column per bucket
		local_fmt="  %-10s"
		printf "$local_fmt" "${BOLD}Month${RESET}"
		for b in "${BUCKET_LIST_MONTHS[@]}"; do
			printf ' %10s' "${BOLD}${b}${RESET}"
		done
		printf '\n'
		printf "$local_fmt" "──────────"
		for b in "${BUCKET_LIST_MONTHS[@]}"; do
			printf ' %10s' "──────────"
		done
		printf '\n'
		for m in "${MONTH_LIST[@]}"; do
			printf "$local_fmt" "$m"
			for b in "${BUCKET_LIST_MONTHS[@]}"; do
				local_val="${MONTHS_MAP["$m|$b"]:-0	0}"
				IFS=$'\t' read -r s _t <<< "$local_val"
				printf ' %10s' "$(format_number "$s")"
			done
			printf '\n'
		done

		section_header "Multi-Month Trends (Tokens)"
		printf '\n'
		printf "$local_fmt" "${BOLD}Month${RESET}"
		for b in "${BUCKET_LIST_MONTHS[@]}"; do
			printf ' %18s' "${BOLD}${b}${RESET}"
		done
		printf '\n'
		printf "$local_fmt" "──────────"
		for b in "${BUCKET_LIST_MONTHS[@]}"; do
			printf ' %18s' "──────────────────"
		done
		printf '\n'
		# Find max tokens for bar scaling
		local_max_tokens=0
		for m in "${MONTH_LIST[@]}"; do
			for b in "${BUCKET_LIST_MONTHS[@]}"; do
				local_val="${MONTHS_MAP["$m|$b"]:-0	0}"
				IFS=$'\t' read -r _s t <<< "$local_val"
				(( t > local_max_tokens )) && local_max_tokens=$t
			done
		done
		for m in "${MONTH_LIST[@]}"; do
			printf "$local_fmt" "$m"
			for b in "${BUCKET_LIST_MONTHS[@]}"; do
				local_val="${MONTHS_MAP["$m|$b"]:-0	0}"
				IFS=$'\t' read -r _s t <<< "$local_val"
				printf ' %18s' "$(format_number "$t")"
			done
			printf '\n'
		done
		printf '\n'

		# Bar chart: tokens per month stacked
		section_header "Monthly Token Distribution"
		printf '\n'
		for m in "${MONTH_LIST[@]}"; do
			# Calculate total for this month
			local_month_total=0
			for b in "${BUCKET_LIST_MONTHS[@]}"; do
				local_val="${MONTHS_MAP["$m|$b"]:-0	0}"
				IFS=$'\t' read -r _s t <<< "$local_val"
				(( local_month_total += t ))
			done
			printf '  %s%-10s%s ' "$BOLD" "$m" "$RESET"
			if (( local_month_total > 0 && local_max_tokens > 0 )); then
				# Scale bar to max month
				local_pct_x100=$(( local_month_total * 10000 / local_max_tokens ))
				local_pct_int=$(( local_pct_x100 / 100 ))
				local_pct_dec=$(( local_pct_x100 % 100 ))
				printf -v local_pct_str '%d.%02d' "$local_pct_int" "$local_pct_dec"
				printf '%s %s\n' "$(make_bar "$local_pct_str")" "$(format_number "$local_month_total")"
			else
				printf '%s %s\n' "$(make_bar "0")" "0"
			fi
		done
		printf '\n'
	else
		printf '\nMulti-month trends\n'
		printf 'month\tbucket\tsessions\ttokens\n'
		printf '%s\n' "$MONTHS_DATA"
	fi
fi

if [[ -n "$ACTUAL_COST_DATA" ]]; then
	# Check if all costs are zero
	all_zero=true
	while IFS=$'\t' read -r bucket cost sessions; do
		if [[ "$cost" != "0" && "$cost" != "0.0" && "$cost" != "0.000000" ]]; then
			all_zero=false
			break
		fi
	done <<< "$ACTUAL_COST_DATA"

	if [[ "$PRETTY" == true ]]; then
		section_header "Actual Cost (Provider-Reported)"
		printf '\n'
		if [[ "$all_zero" == true ]]; then
			printf '  %s(no cost data — your provider does not report costs)%s\n' "$DIM" "$RESET"
		else
			printf '  %-14s %14s %10s\n' \
				"${BOLD}Category${RESET}" "${BOLD}Cost${RESET}" "${BOLD}Sessions${RESET}"
			printf '  %-14s %14s %10s\n' \
				"──────────────" "──────────────" "──────────"
			while IFS=$'\t' read -r bucket cost sessions; do
				printf '  %-14s %13s%s %10s\n' \
					"$bucket" "$CURRENCY" "$cost" "$(format_number "$sessions")"
			done <<< "$ACTUAL_COST_DATA"
		fi
		printf '\n'
	else
		printf '\nActual cost (provider-reported)\n'
		if [[ "$all_zero" == true ]]; then
			printf '(no cost data — your provider does not report costs)\n'
		else
			printf '%s\n' "$ACTUAL_COST_DATA" | (
				printf 'bucket\tcost\tsessions\n'
				cat
			) | format_table
		fi
	fi
fi

if [[ -n "$TODOS_STATUS_DATA" ]]; then
	# Build a map: bucket -> {status: count, ...}
	declare -A TODO_STATUS_MAP
	ALL_STATUSES=()
	declare -A STATUS_SEEN

	while IFS=$'\t' read -r bucket status count; do
		TODO_STATUS_MAP["$bucket|$status"]=$count
		if [[ -z "${STATUS_SEEN[$status]+x}" ]]; then
			STATUS_SEEN[$status]=1
			ALL_STATUSES+=("$status")
		fi
	done <<< "$TODOS_STATUS_DATA"

	if [[ "$PRETTY" == true ]]; then
		section_header "Todo Status by Category"
		printf '\n'
		# Header
		local_fmt="  %-14s"
		printf "$local_fmt" "${BOLD}Category${RESET}"
		for s in "${ALL_STATUSES[@]}"; do
			printf ' %12s' "${BOLD}${s}${RESET}"
		done
		printf ' %12s\n' "${BOLD}total${RESET}"
		printf "$local_fmt" "──────────────"
		for s in "${ALL_STATUSES[@]}"; do
			printf ' %12s' "────────────"
		done
		printf ' %12s\n' "────────────"

		for bucket in "${BUCKETS[@]}"; do
			printf "$local_fmt" "$bucket"
			local_total=0
			for s in "${ALL_STATUSES[@]}"; do
				local_val=${TODO_STATUS_MAP["$bucket|$s"]:-0}
				printf ' %12s' "$(format_number "$local_val")"
				(( local_total += local_val ))
			done
			printf ' %12s\n' "$(format_number "$local_total")"
		done

		# Completion rate
		printf '\n'
		for bucket in "${BUCKETS[@]}"; do
			local_completed=${TODO_STATUS_MAP["$bucket|completed"]:-0}
			local_total=0
			for s in "${ALL_STATUSES[@]}"; do
				(( local_total += ${TODO_STATUS_MAP["$bucket|$s"]:-0} ))
			done
			if (( local_total > 0 )); then
				local_pct=$(( local_completed * 100 / local_total ))
				printf '  %-14s completion: %s %d%%\n' "$bucket" "$(make_bar "$local_pct")" "$local_pct"
			fi
		done
		printf '\n'
	else
		printf '\nTodo status by category\n'
		printf '%s\n' "$TODOS_STATUS_DATA" | (
			printf 'bucket\tstatus\tcount\n'
			cat
		) | format_table
	fi
fi

if [[ -n "$TODOS_PRIORITY_DATA" ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Todo Priority by Category"
		printf '\n'

		declare -A TODO_PRIORITY_MAP
		ALL_PRIORITIES=()
		declare -A PRIORITY_SEEN

		while IFS=$'\t' read -r bucket priority count; do
			TODO_PRIORITY_MAP["$bucket|$priority"]=$count
			if [[ -z "${PRIORITY_SEEN[$priority]+x}" ]]; then
				PRIORITY_SEEN[$priority]=1
				ALL_PRIORITIES+=("$priority")
			fi
		done <<< "$TODOS_PRIORITY_DATA"

		local_fmt="  %-14s"
		printf "$local_fmt" "${BOLD}Category${RESET}"
		for p in "${ALL_PRIORITIES[@]}"; do
			printf ' %10s' "${BOLD}${p}${RESET}"
		done
		printf '\n'
		printf "$local_fmt" "──────────────"
		for p in "${ALL_PRIORITIES[@]}"; do
			printf ' %10s' "──────────"
		done
		printf '\n'

		for bucket in "${BUCKETS[@]}"; do
			printf "$local_fmt" "$bucket"
			for p in "${ALL_PRIORITIES[@]}"; do
				local_val=${TODO_PRIORITY_MAP["$bucket|$p"]:-0}
				printf ' %10s' "$(format_number "$local_val")"
			done
			printf '\n'
		done
		printf '\n'
	else
		printf '\nTodo priority by category\n'
		printf '%s\n' "$TODOS_PRIORITY_DATA" | (
			printf 'bucket\tpriority\tcount\n'
			cat
		) | format_table
	fi
fi

if [[ -n "$FORKS_SUMMARY_DATA" ]]; then
	if [[ "$PRETTY" == true ]]; then
		section_header "Forked Sessions"
		printf '\n'
		printf '  %-14s %10s %10s %10s\n' \
			"${BOLD}Category${RESET}" "${BOLD}Forks${RESET}" "${BOLD}Parents${RESET}" "${BOLD}Avg/Parent${RESET}"
		printf '  %-14s %10s %10s %10s\n' \
			"──────────────" "──────────" "──────────" "──────────"
		while IFS=$'\t' read -r bucket forks parents avg; do
			printf '  %-14s %10s %10s %10s\n' \
				"$bucket" "$(format_number "$forks")" "$(format_number "$parents")" "$avg"
		done <<< "$FORKS_SUMMARY_DATA"

		if [[ -n "$FORKS_TOP_DATA" ]]; then
			printf '\n  %sMost-forked sessions:%s\n' "$DIM" "$RESET"
			local_prev_bucket=""
			while IFS=$'\t' read -r bucket title fork_count; do
				if [[ "$bucket" != "$local_prev_bucket" ]]; then
					printf '\n  %s%s%s\n' "$BOLD" "$bucket" "$RESET"
					local_prev_bucket=$bucket
				fi
				if (( ${#title} > 48 )); then
					title="${title:0:45}..."
				fi
				printf '    %-50s %s forks\n' "$title" "$fork_count"
			done <<< "$FORKS_TOP_DATA"
		fi
		printf '\n'
	else
		printf '\nForked sessions\n'
		printf '%s\n' "$FORKS_SUMMARY_DATA" | (
			printf 'bucket\tforks\tparent_sessions\tavg_forks_per_parent\n'
			cat
		) | format_table
		if [[ -n "$FORKS_TOP_DATA" ]]; then
			printf '\nMost-forked sessions\n'
			printf '%s\n' "$FORKS_TOP_DATA" | (
				printf 'bucket\ttitle\tfork_count\n'
				cat
			) | format_table
		fi
	fi
fi

fi # end OUTPUT_FORMAT
